{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyalink.alink import *\n",
    "useLocalEnv(1)\n",
    "\n",
    "from utils import *\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "pd.set_option('display.max_colwidth', 1000)\n",
    "pd.set_option('display.html.use_mathjax', False)\n",
    "\n",
    "DATA_DIR = ROOT_DIR + \"sentiment_imdb\" + os.sep\n",
    "\n",
    "ORIGIN_DATA_DIR = DATA_DIR + \"aclImdb\" + os.sep\n",
    "\n",
    "TRAIN_FILE = \"train.ak\"\n",
    "TEST_FILE = \"test.ak\"\n",
    "\n",
    "PIPELINE_MODEL = \"pipeline_model.ak\"\n",
    "\n",
    "TXT_COL_NAME = \"review\"\n",
    "LABEL_COL_NAME = \"label\"\n",
    "VECTOR_COL_NAME = \"vec\"\n",
    "PREDICTION_COL_NAME = \"pred\"\n",
    "PRED_DETAIL_COL_NAME = \"predinfo\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#c_1\n",
    "\n",
    "train_set = LibSvmSourceBatchOp()\\\n",
    "    .setFilePath(ORIGIN_DATA_DIR + \"train\" + os.sep + \"labeledBow.feat\")\\\n",
    "    .setStartIndex(0);\n",
    "\n",
    "train_set.lazyPrint(1, \"train_set\");\n",
    "\n",
    "train_set\\\n",
    "    .groupBy(\"label\", \"label, COUNT(label) AS cnt\")\\\n",
    "    .orderBy(\"label\", 100)\\\n",
    "    .lazyPrint(-1, \"labels of train_set\");\n",
    "\n",
    "test_set = LibSvmSourceBatchOp()\\\n",
    "    .setFilePath(ORIGIN_DATA_DIR + \"test\" + os.sep + \"labeledBow.feat\")\\\n",
    "    .setStartIndex(0);\n",
    "\n",
    "test_set\\\n",
    "    .groupBy(\"label\", \"label, COUNT(label) AS cnt\")\\\n",
    "    .orderBy(\"label\", 100)\\\n",
    "    .lazyPrint(-1, \"labels of test_set\");\n",
    "\n",
    "train_set = train_set.select(\"CASE WHEN label>5 THEN 'pos' ELSE 'neg' END AS label, \"\n",
    "                             + \"features AS \" + VECTOR_COL_NAME);\n",
    "test_set = test_set.select(\"CASE WHEN label>5 THEN 'pos' ELSE 'neg' END AS label, \"\n",
    "                           + \"features AS \" + VECTOR_COL_NAME);\n",
    "\n",
    "train_set.lazyPrint(1, \"train_set\");\n",
    "\n",
    "NaiveBayesTextClassifier()\\\n",
    "    .setModelType(\"Multinomial\")\\\n",
    "    .setVectorCol(VECTOR_COL_NAME)\\\n",
    "    .setLabelCol(LABEL_COL_NAME)\\\n",
    "    .setPredictionCol(PREDICTION_COL_NAME)\\\n",
    "    .setPredictionDetailCol(PRED_DETAIL_COL_NAME)\\\n",
    "    .enableLazyPrintModelInfo()\\\n",
    "    .fit(train_set)\\\n",
    "    .transform(test_set)\\\n",
    "    .link(\n",
    "        EvalBinaryClassBatchOp()\\\n",
    "            .setPositiveLabelValueString(\"pos\")\\\n",
    "            .setLabelCol(LABEL_COL_NAME)\\\n",
    "            .setPredictionDetailCol(PRED_DETAIL_COL_NAME)\\\n",
    "            .lazyPrintMetrics(\"NaiveBayesTextClassifier + Multinomial\")\n",
    "    );\n",
    "BatchOperator.execute();\n",
    "\n",
    "Pipeline()\\\n",
    "    .add(\n",
    "        Binarizer()\\\n",
    "            .setSelectedCol(VECTOR_COL_NAME)\\\n",
    "            .enableLazyPrintTransformData(1, \"After Binarizer\")\n",
    "    )\\\n",
    "    .add(\n",
    "        NaiveBayesTextClassifier()\\\n",
    "            .setModelType(\"Bernoulli\")\\\n",
    "            .setVectorCol(VECTOR_COL_NAME)\\\n",
    "            .setLabelCol(LABEL_COL_NAME)\\\n",
    "            .setPredictionCol(PREDICTION_COL_NAME)\\\n",
    "            .setPredictionDetailCol(PRED_DETAIL_COL_NAME)\\\n",
    "            .enableLazyPrintModelInfo()\n",
    "    )\\\n",
    "    .fit(train_set)\\\n",
    "    .transform(test_set)\\\n",
    "    .link(\n",
    "        EvalBinaryClassBatchOp()\\\n",
    "            .setPositiveLabelValueString(\"pos\")\\\n",
    "            .setLabelCol(LABEL_COL_NAME)\\\n",
    "            .setPredictionDetailCol(PRED_DETAIL_COL_NAME)\\\n",
    "            .lazyPrintMetrics(\"Binarizer + NaiveBayesTextClassifier + Bernoulli\")\n",
    "    );\n",
    "BatchOperator.execute();\n",
    "\n",
    "LogisticRegression()\\\n",
    "    .setVectorCol(VECTOR_COL_NAME)\\\n",
    "    .setLabelCol(LABEL_COL_NAME)\\\n",
    "    .setPredictionCol(PREDICTION_COL_NAME)\\\n",
    "    .setPredictionDetailCol(PRED_DETAIL_COL_NAME)\\\n",
    "    .enableLazyPrintTrainInfo(\"< LR train info >\")\\\n",
    "    .enableLazyPrintModelInfo(\"< LR model info >\")\\\n",
    "    .fit(train_set)\\\n",
    "    .transform(test_set)\\\n",
    "    .link(\n",
    "        EvalBinaryClassBatchOp()\\\n",
    "            .setPositiveLabelValueString(\"pos\")\\\n",
    "            .setLabelCol(LABEL_COL_NAME)\\\n",
    "            .setPredictionDetailCol(PRED_DETAIL_COL_NAME)\\\n",
    "            .lazyPrintMetrics(\"LogisticRegression\")\n",
    "    );\n",
    "BatchOperator.execute();\n",
    "\n",
    "\n",
    "lr = LogisticRegression()\\\n",
    "    .setVectorCol(VECTOR_COL_NAME)\\\n",
    "    .setLabelCol(LABEL_COL_NAME)\\\n",
    "    .setPredictionCol(PREDICTION_COL_NAME)\\\n",
    "    .setPredictionDetailCol(PRED_DETAIL_COL_NAME);\n",
    "\n",
    "gridSearch = GridSearchCV()\\\n",
    "    .setEstimator(\n",
    "        Pipeline().add(lr)\n",
    "    )\\\n",
    "    .setParamGrid(\n",
    "        ParamGrid()\\\n",
    "            .addGrid(lr, 'MAX_ITER', [10, 20, 30, 40, 50, 60, 80, 100])\n",
    "    )\\\n",
    "    .setTuningEvaluator(\n",
    "        BinaryClassificationTuningEvaluator()\\\n",
    "            .setLabelCol(LABEL_COL_NAME)\\\n",
    "            .setPredictionDetailCol(PRED_DETAIL_COL_NAME)\\\n",
    "            .setTuningBinaryClassMetric('AUC')\n",
    "    )\\\n",
    "    .setNumFolds(6)\\\n",
    "    .enableLazyPrintTrainInfo();\n",
    "\n",
    "bestModel = gridSearch.fit(train_set);\n",
    "\n",
    "bestModel\\\n",
    "    .transform(test_set)\\\n",
    "    .link(\n",
    "        EvalBinaryClassBatchOp()\\\n",
    "            .setPositiveLabelValueString(\"pos\")\\\n",
    "            .setLabelCol(LABEL_COL_NAME)\\\n",
    "            .setPredictionDetailCol(PRED_DETAIL_COL_NAME)\\\n",
    "            .lazyPrintMetrics(\"LogisticRegression\")\n",
    "    );\n",
    "BatchOperator.execute();\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#c_2\n",
    "\n",
    "if not(os.path.exists(DATA_DIR + TRAIN_FILE)) :\n",
    "    data_arr = []\n",
    "    for label in [\"pos\", \"neg\"] :\n",
    "        file_names = os.listdir(ORIGIN_DATA_DIR + \"train\" + os.sep + label)\n",
    "        for file_name in file_names :\n",
    "            f = open(ORIGIN_DATA_DIR + \"train\" + os.sep + label + os.sep + file_name)\n",
    "            data_arr.append([label, f.read()])\n",
    "            f.close() \n",
    "\n",
    "    BatchOperator\\\n",
    "        .fromDataframe(\n",
    "            pd.DataFrame(data_arr), \n",
    "            schemaStr= LABEL_COL_NAME + ' string, ' + TXT_COL_NAME + ' string'\n",
    "        )\\\n",
    "        .link(\n",
    "            AkSinkBatchOp()\\\n",
    "                .setFilePath(DATA_DIR + TRAIN_FILE)\n",
    "        );\n",
    "    BatchOperator.execute();\n",
    "\n",
    "if not(os.path.exists(DATA_DIR + TEST_FILE)) :\n",
    "    data_arr = []\n",
    "    for label in [\"pos\", \"neg\"] :\n",
    "        file_names = os.listdir(ORIGIN_DATA_DIR + \"test\" + os.sep + label)\n",
    "        for file_name in file_names :\n",
    "            f = open(ORIGIN_DATA_DIR + \"test\" + os.sep + label + os.sep + file_name)\n",
    "            data_arr.append([label, f.read()])\n",
    "            f.close() \n",
    "\n",
    "    BatchOperator\\\n",
    "        .fromDataframe(\n",
    "            pd.DataFrame(data_arr), \n",
    "            schemaStr= LABEL_COL_NAME + ' string, ' + TXT_COL_NAME + ' string'\n",
    "        )\\\n",
    "        .link(\n",
    "            AkSinkBatchOp()\\\n",
    "                .setFilePath(DATA_DIR + TEST_FILE)\n",
    "        );\n",
    "    BatchOperator.execute();\n",
    "\n",
    "\n",
    "train_set = AkSourceBatchOp().setFilePath(DATA_DIR + TRAIN_FILE);\n",
    "test_set = AkSourceBatchOp().setFilePath(DATA_DIR + TEST_FILE);\n",
    "\n",
    "train_set.lazyPrint(2);\n",
    "\n",
    "Pipeline()\\\n",
    "    .add(\n",
    "        RegexTokenizer()\\\n",
    "            .setPattern(\"\\\\W+\")\\\n",
    "            .setSelectedCol(TXT_COL_NAME)\n",
    "    )\\\n",
    "    .add(\n",
    "        DocCountVectorizer()\\\n",
    "            .setFeatureType(\"WORD_COUNT\")\\\n",
    "            .setSelectedCol(TXT_COL_NAME)\\\n",
    "            .setOutputCol(VECTOR_COL_NAME)\\\n",
    "            .enableLazyPrintTransformData(1)\n",
    "    )\\\n",
    "    .add(\n",
    "        LogisticRegression()\\\n",
    "            .setMaxIter(30)\\\n",
    "            .setVectorCol(VECTOR_COL_NAME)\\\n",
    "            .setLabelCol(LABEL_COL_NAME)\\\n",
    "            .setPredictionCol(PREDICTION_COL_NAME)\\\n",
    "            .setPredictionDetailCol(PRED_DETAIL_COL_NAME)\n",
    "    )\\\n",
    "    .fit(train_set)\\\n",
    "    .transform(test_set)\\\n",
    "    .link(\n",
    "        EvalBinaryClassBatchOp()\\\n",
    "            .setPositiveLabelValueString(\"pos\")\\\n",
    "            .setLabelCol(LABEL_COL_NAME)\\\n",
    "            .setPredictionDetailCol(PRED_DETAIL_COL_NAME)\\\n",
    "            .lazyPrintMetrics(\"DocCountVectorizer\")\n",
    "    );\n",
    "BatchOperator.execute();\n",
    "\n",
    "Pipeline()\\\n",
    "    .add(\n",
    "        RegexTokenizer()\\\n",
    "            .setPattern(\"\\\\W+\")\\\n",
    "            .setSelectedCol(TXT_COL_NAME)\n",
    "    )\\\n",
    "    .add(\n",
    "        DocHashCountVectorizer()\\\n",
    "            .setFeatureType(\"WORD_COUNT\")\\\n",
    "            .setSelectedCol(TXT_COL_NAME)\\\n",
    "            .setOutputCol(VECTOR_COL_NAME)\\\n",
    "            .enableLazyPrintTransformData(1)\n",
    "    )\\\n",
    "    .add(\n",
    "        LogisticRegression()\\\n",
    "            .setMaxIter(30)\\\n",
    "            .setVectorCol(VECTOR_COL_NAME)\\\n",
    "            .setLabelCol(LABEL_COL_NAME)\\\n",
    "            .setPredictionCol(PREDICTION_COL_NAME)\\\n",
    "            .setPredictionDetailCol(PRED_DETAIL_COL_NAME)\n",
    "    )\\\n",
    "    .fit(train_set)\\\n",
    "    .transform(test_set)\\\n",
    "    .link(\n",
    "        EvalBinaryClassBatchOp()\\\n",
    "            .setPositiveLabelValueString(\"pos\")\\\n",
    "            .setLabelCol(LABEL_COL_NAME)\\\n",
    "            .setPredictionDetailCol(PRED_DETAIL_COL_NAME)\\\n",
    "            .lazyPrintMetrics(\"DocHashCountVectorizer\")\n",
    "    );\n",
    "BatchOperator.execute();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#c_3\n",
    "\n",
    "useLocalEnv(4)\n",
    "\n",
    "train_set = AkSourceBatchOp().setFilePath(DATA_DIR + TRAIN_FILE);\n",
    "test_set = AkSourceBatchOp().setFilePath(DATA_DIR + TEST_FILE);\n",
    "\n",
    "Pipeline()\\\n",
    "    .add(\n",
    "        RegexTokenizer()\\\n",
    "            .setPattern(\"\\\\W+\")\\\n",
    "            .setSelectedCol(TXT_COL_NAME)\n",
    "    )\\\n",
    "    .add(\n",
    "        DocCountVectorizer()\\\n",
    "            .setFeatureType(\"WORD_COUNT\")\\\n",
    "            .setSelectedCol(TXT_COL_NAME)\\\n",
    "            .setOutputCol(VECTOR_COL_NAME)\n",
    "    )\\\n",
    "    .add(\n",
    "        NGram()\\\n",
    "            .setN(2)\\\n",
    "            .setSelectedCol(TXT_COL_NAME)\\\n",
    "            .setOutputCol(\"v_2\")\\\n",
    "            .enableLazyPrintTransformData(1, \"2-gram\")\n",
    "    )\\\n",
    "    .add(\n",
    "        DocCountVectorizer()\\\n",
    "            .setFeatureType(\"WORD_COUNT\")\\\n",
    "            .setSelectedCol(\"v_2\")\\\n",
    "            .setOutputCol(\"v_2\")\n",
    "    )\\\n",
    "    .add(\n",
    "        VectorAssembler()\\\n",
    "            .setSelectedCols([VECTOR_COL_NAME, \"v_2\"])\\\n",
    "            .setOutputCol(VECTOR_COL_NAME)\n",
    "    )\\\n",
    "    .add(\n",
    "        LogisticRegression()\\\n",
    "            .setMaxIter(30)\\\n",
    "            .setVectorCol(VECTOR_COL_NAME)\\\n",
    "            .setLabelCol(LABEL_COL_NAME)\\\n",
    "            .setPredictionCol(PREDICTION_COL_NAME)\\\n",
    "            .setPredictionDetailCol(PRED_DETAIL_COL_NAME)\n",
    "    )\\\n",
    "    .fit(train_set)\\\n",
    "    .transform(test_set)\\\n",
    "    .link(\n",
    "        EvalBinaryClassBatchOp()\\\n",
    "            .setPositiveLabelValueString(\"pos\")\\\n",
    "            .setLabelCol(LABEL_COL_NAME)\\\n",
    "            .setPredictionDetailCol(PRED_DETAIL_COL_NAME)\\\n",
    "            .lazyPrintMetrics(\"NGram 2\")\n",
    "    );\n",
    "BatchOperator.execute();\n",
    "\n",
    "Pipeline()\\\n",
    "    .add(\n",
    "        RegexTokenizer()\\\n",
    "            .setPattern(\"\\\\W+\")\\\n",
    "            .setSelectedCol(TXT_COL_NAME)\n",
    "    )\\\n",
    "    .add(\n",
    "        DocCountVectorizer()\\\n",
    "            .setFeatureType(\"WORD_COUNT\")\\\n",
    "            .setSelectedCol(TXT_COL_NAME)\\\n",
    "            .setOutputCol(VECTOR_COL_NAME)\n",
    "    )\\\n",
    "    .add(\n",
    "        NGram()\\\n",
    "            .setN(2)\\\n",
    "            .setSelectedCol(TXT_COL_NAME)\\\n",
    "            .setOutputCol(\"v_2\")\n",
    "    )\\\n",
    "    .add(\n",
    "        DocCountVectorizer()\\\n",
    "            .setFeatureType(\"WORD_COUNT\")\\\n",
    "            .setSelectedCol(\"v_2\")\\\n",
    "            .setOutputCol(\"v_2\")\n",
    "    )\\\n",
    "    .add(\n",
    "        NGram()\\\n",
    "            .setN(3)\\\n",
    "            .setSelectedCol(TXT_COL_NAME)\\\n",
    "            .setOutputCol(\"v_3\")\n",
    "    )\\\n",
    "    .add(\n",
    "        DocCountVectorizer()\\\n",
    "            .setFeatureType(\"WORD_COUNT\")\\\n",
    "            .setVocabSize(10000)\\\n",
    "            .setSelectedCol(\"v_3\")\\\n",
    "            .setOutputCol(\"v_3\")\n",
    "    )\\\n",
    "    .add(\n",
    "        VectorAssembler()\\\n",
    "            .setSelectedCols([VECTOR_COL_NAME, \"v_2\", \"v_3\"])\\\n",
    "            .setOutputCol(VECTOR_COL_NAME)\\\n",
    "    )\\\n",
    "    .add(\n",
    "        LogisticRegression()\\\n",
    "            .setMaxIter(30)\\\n",
    "            .setVectorCol(VECTOR_COL_NAME)\\\n",
    "            .setLabelCol(LABEL_COL_NAME)\\\n",
    "            .setPredictionCol(PREDICTION_COL_NAME)\\\n",
    "            .setPredictionDetailCol(PRED_DETAIL_COL_NAME)\n",
    "    )\\\n",
    "    .fit(train_set)\\\n",
    "    .transform(test_set)\\\n",
    "    .link(\n",
    "        EvalBinaryClassBatchOp()\\\n",
    "            .setPositiveLabelValueString(\"pos\")\\\n",
    "            .setLabelCol(LABEL_COL_NAME)\\\n",
    "            .setPredictionDetailCol(PRED_DETAIL_COL_NAME)\\\n",
    "            .lazyPrintMetrics(\"NGram 2 and 3\")\n",
    "    );\n",
    "BatchOperator.execute();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#c_4\n",
    "\n",
    "train_set = AkSourceBatchOp().setFilePath(DATA_DIR + TRAIN_FILE);\n",
    "\n",
    "if not(os.path.exists(DATA_DIR + PIPELINE_MODEL)) :\n",
    "    Pipeline()\\\n",
    "        .add(\n",
    "            RegexTokenizer()\\\n",
    "                .setPattern(\"\\\\W+\")\\\n",
    "                .setSelectedCol(TXT_COL_NAME)\n",
    "        )\\\n",
    "        .add(\n",
    "            DocCountVectorizer()\\\n",
    "                .setFeatureType(\"WORD_COUNT\")\\\n",
    "                .setSelectedCol(TXT_COL_NAME)\\\n",
    "                .setOutputCol(VECTOR_COL_NAME)\n",
    "        )\\\n",
    "        .add(\n",
    "            NGram()\\\n",
    "                .setN(2)\\\n",
    "                .setSelectedCol(TXT_COL_NAME)\\\n",
    "                .setOutputCol(\"v_2\")\n",
    "        )\\\n",
    "        .add(\n",
    "            DocCountVectorizer()\\\n",
    "                .setFeatureType(\"WORD_COUNT\")\\\n",
    "                .setVocabSize(50000)\\\n",
    "                .setSelectedCol(\"v_2\")\\\n",
    "                .setOutputCol(\"v_2\")\n",
    "        )\\\n",
    "        .add(\n",
    "            NGram()\\\n",
    "                .setN(3)\\\n",
    "                .setSelectedCol(TXT_COL_NAME)\\\n",
    "                .setOutputCol(\"v_3\")\n",
    "        )\\\n",
    "        .add(\n",
    "            DocCountVectorizer()\\\n",
    "                .setFeatureType(\"WORD_COUNT\")\\\n",
    "                .setVocabSize(10000)\\\n",
    "                .setSelectedCol(\"v_3\")\\\n",
    "                .setOutputCol(\"v_3\")\n",
    "        )\\\n",
    "        .add(\n",
    "            VectorAssembler()\\\n",
    "                .setSelectedCols([VECTOR_COL_NAME, \"v_2\", \"v_3\"])\\\n",
    "                .setOutputCol(VECTOR_COL_NAME)\n",
    "        )\\\n",
    "        .add(\n",
    "            LogisticRegression()\\\n",
    "                .setMaxIter(30)\\\n",
    "                .setVectorCol(VECTOR_COL_NAME)\\\n",
    "                .setLabelCol(LABEL_COL_NAME)\\\n",
    "                .setPredictionCol(PREDICTION_COL_NAME)\\\n",
    "                .setPredictionDetailCol(PRED_DETAIL_COL_NAME)\n",
    "        )\\\n",
    "        .fit(train_set)\\\n",
    "        .save(DATA_DIR + PIPELINE_MODEL);\n",
    "    BatchOperator.execute();\n",
    "\n",
    "\n",
    "pipeline_model = PipelineModel.load(DATA_DIR + PIPELINE_MODEL);\n",
    "\n",
    "test_set = AkSourceBatchOp().setFilePath(DATA_DIR + TEST_FILE);\n",
    "\n",
    "pipeline_model\\\n",
    "    .transform(test_set)\\\n",
    "    .link(\n",
    "        EvalBinaryClassBatchOp()\\\n",
    "            .setPositiveLabelValueString(\"pos\")\\\n",
    "            .setLabelCol(LABEL_COL_NAME)\\\n",
    "            .setPredictionDetailCol(PRED_DETAIL_COL_NAME)\\\n",
    "            .lazyPrintMetrics(\"NGram 2 and 3\")\n",
    "    );\n",
    "BatchOperator.execute();\n",
    "\n",
    "test_stream = AkSourceStreamOp().setFilePath(DATA_DIR + TEST_FILE);\n",
    "pipeline_model\\\n",
    "    .transform(test_stream)\\\n",
    "    .sample(0.001)\\\n",
    "    .select(PREDICTION_COL_NAME + \", \" + LABEL_COL_NAME + \", \" + TXT_COL_NAME)\\\n",
    "    .print();\n",
    "StreamOperator.execute();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "review_str\\\n",
    "= \"Oh dear. good cast, but to write and direct is an art and to write wit and direct wit is a bit of a \"\\\n",
    "+ \"task. Even doing good comedy you have to get the timing and moment right. Im not putting it all down \"\\\n",
    "+ \"there were parts where i laughed loud but that was at very few times. The main focus to me was on the \"\\\n",
    "+ \"fast free flowing dialogue, that made some people in the film annoying. It may sound great while \"\\\n",
    "+ \"reading the script in your head but getting that out and to the camera is a different task. And the \"\\\n",
    "+ \"hand held camera work does give energy to few parts of the film. Overall direction was good but the \"\\\n",
    "+ \"script was not all that to me, but I'm sure you was reading the script in your head it would sound good\"\\\n",
    "+ \". Sorry.\";\n",
    "\n",
    "local_predictor = pipeline_model.collectLocalPredictor(\"review string\");\n",
    "\n",
    "print(local_predictor.getOutputColNames());\n",
    "\n",
    "pred_row = local_predictor.map([review_str]);\n",
    "\n",
    "print(pred_row[4]);\n",
    "\n",
    "\n",
    "local_predictor_2 = LocalPredictor(DATA_DIR + PIPELINE_MODEL, \"review string\");\n",
    "\n",
    "print(local_predictor_2.getOutputColNames());\n",
    "\n",
    "pred_row = local_predictor_2.map([review_str]);\n",
    "\n",
    "print(pred_row[4]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
